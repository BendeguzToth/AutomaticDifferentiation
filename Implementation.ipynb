{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The implementation of the Transformer\n",
    "\n",
    "The Encoder receives a rank 3 tensor as input. The dimensions of that input are (Batch, Feature length, sequence length). Where feature length refers to $d_{model}$ from the original paper, and is the length of the token embeddings. Sequence length refers to the amount of tokens in the sequence. In the future we will refer to this as `(BxFxS)`. This means that the features are column vectors. Concatenating them along the 2nd axis gives a matrix, with `S` columns and `F` rows.\n",
    "$$\\left[\\matrix{a&b\\\\c&d}\\right]$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.8_Full",
   "language": "python",
   "name": "3.6.8_full"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
